{"componentChunkName":"component---src-templates-project-post-js","path":"/gymnasium-rl/","result":{"data":{"site":{"siteMetadata":{"title":"Notebook"}},"markdownRemark":{"id":"652f889a-7208-5330-b450-a76c17d03e5f","excerpt":"I’m currently working through the Gymnasium documentation and implementing classic Reinforcement Learning algorithms from scratch (and with libraries like…","html":"<p>I’m currently working through the <a href=\"https://gymnasium.farama.org\">Gymnasium</a> documentation and implementing classic Reinforcement Learning algorithms from scratch (and with libraries like Stable Baselines3).</p>\n<h2>Current Focus</h2>\n<ul>\n<li><strong>Algorithm:</strong> Proximal Policy Optimization (PPO)</li>\n<li><strong>Environment:</strong> LunarLander-v2 and CartPole-v1</li>\n</ul>\n<p>It is surprisingly challenging to tune the hyperparameters. The agent often gets stuck in local optima. I plan to write a full blog post breakdown of my PPO implementation once I get it consistently solving the harder environments.</p>","frontmatter":{"title":"Reinforcement Learning with Gymnasium","date":"February 01, 2026","description":"Implementing PPO algorithms on various Gymnasium environments to understand RL fundamentals.","status":"in-progress","tags":["ai","reinforcement-learning","python"],"thumbnail":"https://gymnasium.farama.org/_images/cart_pole.gif"}}},"pageContext":{"slug":"/gymnasium-rl/","previous":{"fields":{"slug":"/kumiko-frame/","collection":"projects"},"frontmatter":{"title":"Large Kumiko Frame"}},"next":{"fields":{"slug":"/3d-printed-speakers/","collection":"projects"},"frontmatter":{"title":"3D Printed Speakers"}}}},"staticQueryHashes":["3000541721","3391161144"],"slicesMap":{}}